# multimodal_plausibility
To identify plausible language priors are dominant in MLLMs over visual evidence.

Dataset used: POPE
Model used: Llava-1.6

Corruption levels: ["original","no_visual","light_blur","medium_blur","heavy_blur","slight_noise","noise"]
Prompts: ["Default","Report Uncertainity","Abstention allowed"]

To run the code:
```python3 main.py```

Different files are added for the presented plots. 
